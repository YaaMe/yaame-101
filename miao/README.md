喵

不用怀疑，就是喵

其实就是一些胡思乱想（喵言喵语）

主要有一些碎片也好，灵感也好，其实并不知道属于哪一个分类，但是又不想扔在最上层碎碎念。

其实应该目录跟自己codename同名，但那样目录会有点怪，想了想那就喵吧。

### 简单说下自己的记忆结构。

首先在创造自己的记忆结构前我是真的不知道[记忆宫殿](https://wiki.mbalib.com/wiki/%E8%AE%B0%E5%BF%86%E5%AE%AB%E6%AE%BF)这么个鬼玩意儿的，后来我仔细想了想，以我的从小对着七巧板两眼懵圈的艺术细胞，想让我建个宫殿那可能有点天方夜谭_(:_」∠)_

我的记忆结构是个类球型，首先肯定不能是平面，会遇到四色问题，当然那时候可能也不知道四色问题是个什么玩意儿，只是平面上隔着两块地图无法相连是个很明显的问题。

每一个记录的东西是一个点，若干个点组成一个区域，点与点之间的连线代表这两个点之间的逻辑关系，连线上微观会继续产生新的点，作为逻辑的补充关系填入。越核心的区域，存放越抽象和接近事物本质的东西，越外层的区域，越接近实际的生活与知识点，比如哲学会坐落在数学里层，美术空间构成会从数学的某个区域展开。不需要记忆非常绝对的层级距离，相关的领域放在靠近的位置，不在相邻的四周也没关系，可以往内走一层再联系过去。某个点本身可能后演变成区域，作为这个知识点的详细展开。这样如果以过球心的方向去切开这个球，你会得到一颗树，很少遇到过图。如果root点是公设/公理，那么往上一层，也许是一阶逻辑，就会是最简单的定理，再继续往上，会得到整个理论体系。如果你往球面的方向去看，放大后会得到一个平面，以透视的方式看，你会得到一个向四周发散的网状图，可能类似一个roadmap，但越靠近中心的内容从概率上点会越多一点。因此当我尝试学习一个新的事物时，我总是会从已知的内容上去尝试建立联系，发现错误就修正。暂时无法理解的内容就随机地扔在你所选择的领域附近。直到某天能将碎片打碎与某些点建立链接。

这样做的一个好处/坏处是你的思维跳跃会非常快，因为只是往内跃迁了一层（跳跃的方式并不是点，因为某一个区域/块级本身也可以视为一个点），然后就瞬间能跳跃到别的领域上去。
第二个特点是，你会发现这些点有相当多的[分形](https://zh.m.wikipedia.org/zh-hans/%E5%88%86%E5%BD%A2)结构，在你接触一个新概念后，如果你发现你对其构筑最开始的几个点有相似的分形，得益于内层依赖你会立即得到一些有意思的推定结论，逐一验证这些结论是否正确即可以跳跃的方式从抽象层面理解和完成体系上的推论。
第三个比较尴尬的地方是，基于这种结构当我需要向别人阐述某个领域的内容时，我可能抛出的是尽可能接近底层的公设或者原则，但一般人都很难理解，所以我表达能力其实很差。举个例子，你把欧几五大公设列一遍，我见过都多数人都是一脸懵，但是你掏出一个直角三角形，对方会表示很直观，并推论三角函数，对方会更容易理解和接受，而这种三角是基于欧几公设之上，不知道几阶的逻辑推论了……这种情况我想要跟人解释清楚我只能二分不段地寻找分叉点……另一个例子是：我跟人解释react和vue的区别，我说react认为state是不变的，vue认为state是可变的，前者基于事件变化，后者基于数据变化。反正听到的人都是一脸：你在说啥不明觉厉的感觉。而基于这个的推论却更容易被理解：以用户登录为例，user从未登录状态变为登录状态，由于react的state是不变的，所以你永远不可能/不该在用户未登录的逻辑后面拿到用户登录状态的值，所以判断用户登录状态的component一定在执行登录事件的dom上层。所以逻辑一定是，先判断用户登录状态，未登录：给登录action，重新指回登录状态，已登录，拿状态值。
还有个坏处是：这个记忆结构在量上没什么优势，比如词汇量，因为很明显矢量图，存量是需要磁盘阵列的，但从另一个角度说，你需要找到词根词缀扩散，扩展到整个语系或许也还可以……但这也意味着，你其实还是需要花大量的时间去磨。

ps: 目前我并不知道其他人的记忆结构是怎么样的。我也并非是说自己的结构是好还是不好，单纯只是介绍。

从物理学的角度说：一个概念具有定义式和计算式的差别。加速度是描述物体运动变化快慢的物理量，所以 a=v/t，但加速度的计算式可以有很多种a=F/m等。那么在物理学里，一个概念的记忆点描述会是定义式，与其他物理量的描述会是计算式。当一个物理题被抛给我，理解这个问题后我首先会找这个问题在球的位置。找寻最多相关的物理量，然后找要求的解的所在位置，然后就是一个类似寻路算法的工作机制（一般我会放在球面网状的结构上找）。于是就能构成一条[假言三段论](https://zh.m.wikipedia.org/zh-hans/%E5%81%87%E8%A8%80%E4%B8%89%E6%AE%B5%E8%AE%BA)式的推理逻辑线：有了A我就能计算B，有了B我就能知道C。

所以树型的结构主要进行学习，理解，推理，假设，断言，网状的结构主要进行验证，执行，视角可以任意切换，取决于跳跃的方向。

对一件实际事件进行推理的时候，如果不能停靠在具体的某一个点上，我会同时选择若干个区域内的若干个点，同时发散出去。但我不能很好地完成多线程的工作，所以还是更倾向跳几个点后先找到主观意义上最有价值的一个点，推理完，然后再挑选几个次要点推理。

文学模型的话，我不知道宫殿的结构是否会更合适，但是不同的文字，描述的事物，感情，颜色，时代，同样可以被拆解到几个相关的点，然后被重新聚合关联。

以上就是我对文理模型的记忆结构说明。哦，主要的坏处大概是容易咕咕，因为一件事情被解析完可能真的已经过去了很久，要从头表述真的很困难。
